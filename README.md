![123](https://user-images.githubusercontent.com/92734524/216488983-67aa4c36-9e6c-4801-b558-ce404be8605b.jpeg)

<h1>Pequenos projetos utilizando ferramentas do esossistema HADOOP</h1>
 
Neste repositório irei apresentar pequenos projetos no qual utilizo as ferramentas do ecossistema Hadoop aprendidas durante o curso: 
*Engenharia de dados com Hadoop e Spark*. Os projetos aqui realizados utilizarão datasets de diversas fontes e áreas de negócios, 
tendo em vista que o objetivo principal é demonstrar o aprendizado adquirido durante o curso de formação ma Data Science Academy. 

# Tabela de conteúdos 

1. [Ferramentas](https://github.com/CaioBrainer/hadoop_ecosystem_little_projects#ferramentas)

2. [Projetos](https://github.com/CaioBrainer/hadoop_ecosystem_little_projects#projetos)
   - [Job Map Reduce com Hadoop e MRJob](https://github.com/CaioBrainer/hadoop_ecosystem_little_projects##job_map_reduce_com_hadoop_e_mrjob)
   - [Job Map Reduce com Hadoop Streaming](https://github.com/CaioBrainer/hadoop_ecosystem_little_projects##Job_map_reduce_com_hadoop_streaming)

# Ferramentas

As principais ferramentas utilizadas são os componentes do ecossistema Hadoop no SO linux Ubuntu 22.04. Abaixo segue a lista das versões utilizadas:

- Apache Hadoop 3.3.1
- Apache Hive 3.1.2
- Apache Spark 3.3.1
- Miniconda 3
- MRJob

# Projetos

## Job Map Reduce com Hadoop e MRJob

## Job Map Reduce com Hadoop Streaming


